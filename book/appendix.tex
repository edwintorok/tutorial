\part{Appendix}

\newpage



%\chapter{Theses}
\hypertarget{Acknowledgement}{%
\section{Acknowledgement}\label{acknowledgement}}

Owl is built on top of an enormous amount of previous work. Without the efforts of these projects and the intellectual contribution of these people, it will be very difficult for me to continue developing Owl.

We thank our sponsors all the contributors, Owl can grow and help many people in solving various real world problems because of their generous support.

OCaml Labs has been providing various types of support including computation resources, internship and studentship revolving around Owl’s research and development.



\newpage



%\chapter{Theses}
\hypertarget{Theses}{%
\section{Theses}\label{theses}}

\hypertarget{Probabilistic Synchronous Parallel}{%
\subsection{Probabilistic Synchronous Parallel}\label{theses-psp}}

By Benjamin P. W. Catterall | Part III | June 2017

The synchronisation scheme used to manage parallel updates of a distributed machine learning model can dramatically impact performance. System and algorithm designers need methods which allow them to make trade-offs between fully asynchronous and fully deterministic schemes. Barrier control methods represent one possible solution. In this report, I present Probabilistic Synchronous Parallel (PSP), a barrier control method for distributed machine learning. I provide analytical proofs of convergence and carry out an experimental verification of the method using a bespoke simulator. I find that PSP improves the convergence speed and iteration throughput of more traditional barrier control methods. Furthermore, I demonstrate that PSP provides stronger convergence guarantees than a fully asynchronous design whilst maintaining the general characteristics of stronger methods.


\hypertarget{Supporting Browser-based Machine Learning}{%
\subsection{Supporting Browser-based Machine Learning}\label{theses-webml}}

By Tudor Petru Tiplea | Part III | June 2018

Because it can tell so much about nature and people, digital data is collected and analysed in immeasurable quantities. Processing this data often requires collections of resources typically organised in massive data centres, a paradigm known as cloud computing. However, this paradigm has certain limitations. Apart from the often prohibitive costs, cloud computing requires data centralisation, which could slow down real-time applications, or require exorbitant storage. Edge computing—a solution aiming to move computation to the network's edge — is regarded as a promising alternative, especially when tailored for Internet-of-Things deployment.

Aiming for more large-scale adoption, this project provides a proof of concept for edge computing support on an ubiquitous platform—the web-browser. This work is framed within an emerging OCaml ecosystem for data processing and machine learning applications. We explored options for OCaml-to-JavaScript compilation, and extended Owl, the main library in the ecosystem, guided by those findings. Next, we researched solutions for efficient data transmissions between browsers, then based on that, implemented a browser-compatible communication system analogous to TCP/IP network sockets. This system was later used to modify Actor, Owl's distributed computing engine, making it deployable in the browser.

We demonstrated our work on Owl was successful, exemplifying the browser-deployed localised computing capabilities. The performance limitations of this part were analysed, and we suggest directions for optimisations based on empirical results. We also illustrated the accomplishment of browser-based distributed computing, again identifying limitations that must be overcome in the future for a complete solution.


\hypertarget{Adaptable Asynchrony in Distributed Learning}{%
\subsection{Adaptable Asynchrony in Distributed Learning}\label{theses-adapt}}

By De Sheng Royson Lee | M.Phil | June 2018

Distributed training of deep learning models is typically trained using stochastic optimisation in an asynchronous or synchronous environment. Increasing asynchrony is known to add noise introduced from stale gradient updates, whereas relying on synchrony may be inefficient due to stragglers. Although there has been a wide range of approaches to mitigate or even negate these weaknesses, little has been done to improve asynchronous adaptive stochastic gradient descent (SGD) optimisation. In this report, I survey these approaches and propose a technique to better train these models. In addition, I empirically show that the technique works well with delay-tolerance adaptive SGD optimisation algorithms, improving the rate of convergence, stability, and test accuracy. I also demonstrate that my approach performs consistently well in a dynamic environment in which the number of workers changes uniformly at random.


\hypertarget{Applications of Linear Types}{%
\subsection{Applications of Linear Types}\label{theses-linear}}

By Dhruv C. Makwana | Part III | June 2018

In this thesis, I argue that linear types are an appropriate, type-based formalism for expressing aliasing, read/write permissions, memory allocation, re-use and deallocation, first, in the context of the APIs of linear algebra libraries and then in the context of matrix expression compilation. I show that framing the problem using linear types can reduce bugs by making precise and explicit, the informal, ad-hoc practices typically employed by experts and matrix expression compilers and automate checking them.

As evidence for this argument, I show non-trivial, yet readable, linear algebra programs, that are safe and explicit (with respect to aliasing, read/write permissions, memory allocation, re-use and deallocation) which (1) are more memory-efficient than equivalent programs written using high- level linear algebra libraries and (2) perform just as predictably as equivalent programs written using low-level linear algebra libraries. I also argue the experience of writing such programs with linear types is qualitatively better in key respects. In addition to all of this, I show that it is possible to provide such features as a library on top of existing programming languages and linear algebra libraries.


\hypertarget{Composing Data Analytical Services}{%
\subsection{Composing Data Analytical Services}\label{theses-zoo}}

By Jianxin Zhao | PhD | June 2018

Data analytics on the cloud is known to have issues such as increased response latency, communication cost, single point failure, and data privacy concerns. While moving analytics from cloud to edge devices has recently gained rapid growth in both academia and industry, this topic still faces many challenges such as limited computation resource on the edge. In this report, we further identify two main challenges: the composition and deployment of data analytics services on edge devices. Initially, the Zoo system is designed to make it convenient for developers to share and execute their OCaml code snippets, with fine-grained version control mechanism. We then extend it to address those two challenges. On one hand, Zoo provides simple domain-specific language and high-level types to enable easy and type-safe composition of different data analytics services. On the other hand, it utilises multiple deployment backends, including Docker container, JavaScript, and MirageOS, to accommodate the heterogeneous edge deployment environment. We demonstrate the expressiveness of Zoo with a use case, and thoroughly compare the performance of different deployment backends in evaluation.


\hypertarget{Computer Vision in OCaml}{%
\subsection{Computer Vision in OCaml}\label{theses-vision}}

By Pierre Vandenhove | MSc | October 2018

Computer vision tasks are known to be highly computationally-heavy, both performance-wise and memory-wise. They are thus especially relevant to put a numerical framework such as Owl to the test. The first part of this project focuses on the implementation of several computer vision applications using Owl's neural network library. The first such application is Microsoft's ‘ResNet' network to perform simple image classification (paper 1512.03385, Resnet implementation in Owl). The second, more extensive one, is ‘Mask R-CNN', which is one of the leading networks to perform object detection, segmentation and classification (paper 1703.06870, MRCNN implementation). This allowed exemplifying some use cases to improve Owl's flexibility and ease of use, as well as add some necessary operations.

These applications are valuable benchmarking tools to identify bottlenecks and guide the optimisation of different subcomponents of Owl. A crucial step in this process is to apply Owl's computation graph to them, which is the key to obtaining state-of-the-art performance and memory usage. With the new applications as examples, it was possible to make it more robust, efficient and user-friendly.


\hypertarget{Automatic Parameter Tuning for OpenMP}{%
\subsection{Automatic Parameter Tuning for OpenMP}\label{theses-aeos}}

By Jianxin Zhao | PhD | November 2018

Automatic Empirical Optimisation of Software (AEOS) is crucial for high performance computing software. It is a methodology to generate optimised software using empirically tuned parameters. As an initial attempt to improve the performance of Owl with it, we build the AEOS module to tune the OpenMP parameters in Owl. OpenMP is an application programming interface that supports multi-platform shared memory multiprocessing programming. It is used in Owl to boost performance of basic operations. However, using OpenMP brings certain overhead, so that when the size of input data is small, or the operation is simple, the non-OpenMP version operation might be faster. Thus an optimal threshold varies for different operations and machines. In the AEOS module, each operation is abstracted as a stand-alone module, and uses linear regression to find this optimal threshold. Compared with the previous practice of set a single threshold for all OpenMP operations, using AEOS module further improves their performance. The AEOS module is designed in such way that extending it to accommodate more parameters or operations should be easy.


\hypertarget{Run Your Owl Computation on TensorFlow}{%
\subsection{Run Your Owl Computation on TensorFlow}\label{theses-tf}}

By Jianxin Zhao | PhD | February 2019

In this project we are looking at computation interoperability of Owl with existing libraries such as TensorFlow. Our target is to have the best of both worlds. On one hand, we can define “how to compute” on Owl with its elegant and powerful syntax; on the other hand, we can execute the computation efficiently across various hardware devices, such as GPU and TPU, that TensorFlow supports. One crucial decision to make is to find the correct intermediate representation in exchanging computation between different platforms. Unlike many existing systems and tools, we decide that computation graph, rather than neural network graph, should be the fundamental abstraction. Based on this decision, we build an experimental converter system. It aims to export CGraph defined in Owl and execute it in TensorFlow. This system centres around the abstraction of TensorFlow computation graph, and how to map Owl computation graph to it. Our system utilises the Save and Restore mechanism in TensorFlow to provide a concise workflow. Currently we are actively developing the system. Thought still quite limited at the initial phase, the system has shown its potential in real-world examples, including deep neural network inference and algorithmic differentiation. In our next step, it would be interesting to see how our system can be extended and combined with related topics such as GPU and XLA.


\hypertarget{Ordinary Differential Equation Solver}{%
\subsection{Ordinary Differential Equation Solver}\label{theses-owlde}}

By Ta-Chu Kao and Marcello Seri | July 2019

Owl Ode is a lightweight package for solving ordinary differential equations. Built on top of Owl's numerical library, Owl Ode was designed with extensibility and ease of use in mind and includes a number of classic ode solvers (e.g. Euler and Runge-Kutta, in both adaptive and fixed-step variants) and symplectic sovlers (e.g. Leapfrog), with more to come. Taking full advantage of Owl's automatic differentiation library, we plan on supporting a number of fully differentiable solvers, which can be used, for example, for training Neural Odes.

Currently, Owl Ode includes separately-released thin wrappers around Sundials Cvode (via sundialsml's own wrapper) and ODEPACK, native ocaml contact variational integrators, and exposes a fully native ocaml module compatible with js\_of\_ocaml (owl-ode-base). Going forward, we aim to expose more functions in Sundials, make the API even more flexible and configurable, and provide bindings for other battle-tested ODE solvers.

\newpage



\hypertarget{Resources}{%
\section{Resources}\label{resources}}

list some useful links here

\newpage



\hypertarget{Epilogue}{%
\section{Epilogue}\label{epilogue}}

Back in the summer of 2019, Liang and I were considering the maintenance of Owl's documentation. We were glad that the documentation serve us well and was growing day by day.
Then somehow it occurred to us that, now that we have such a large documentation at hand, as well as paper drafts and blogs etc., why don't we put these different pieces together into something like a tutorial book.
That's basically the root of this book.

We then discussed the possible ways to organise the book.
One obvious and convenient way is to extending the existing materials according to the different modules of Owl.
However, while the architectures of Owl may change easily in the future, the topic of scientific computing does not.
In the end, we decided to more or less follow the outlines of the traditional textbooks in scientific computing and numerical computing etc.
However, we do not intend to make it yet another data science/machine learning/numerical computing algorithm book, and you may find this book a little bit different.

The whole book is divided into three parts.
The first part "numerical techniques" covers a wide range of topics.
The Statistics and Linear Algebra are traditional mathematical topics;
manipulation and slicing of ndarray belongs to the introductory part of a language;
visualisation and dataframes are often placed in the first chapter of a data science book;
differential equation, signal processing, and optimisation are among the core topics of numerical methods;
regression, DNN, and NLP are surely covered in numerous Machine Learning books.
There is also AD, the topic that is less mentioned but nevertheless extremely important.
The reason we mix all these topics together is that, instead of letting the content of book to follow the structure of Owl, we want Owl to follow as many topics as possible that are related to scientific computing, and check our coverage of them.
We are glad to find out that Owl can be of help in most of these listed topics.
Also, it provides a good guidance for our next step development.

The second part is about system architecture of Owl. Most of the topics discussed here, such as distributed computing, low level optimisation, computation graph, etc. are not often seen in other books.
Maybe they are too academic for general readers.
However, as the creator and developer of Owl, what we can provide is not just ``how to use it'', but also ``how it is built''.

The third part demonstrates several cases. While the foundation of scientific computing is solid and concrete, its applications are springing out at an astounding speed.
Each chapter shows one sophisticated real world use case of Owl.
Currently we have three computer vision applications: image recognition, instance segmentation, and style transfer. They are widely used in the state-of-art technologies.
The recommender system is also based on a product Kvasir that's deployed in the production environment.
% The finance chapter
This part is meant to be extendable.
We are very interested to add more cases contributed by experts from other fields and disciplines.

So that's a brief explanation about the organisation of this book. I feel obliged to explain to those readers who are confused about the theme of this book.
No doubt that there are still a lot to be improved about this book.
Almost all the chapters in the first part can be extended to at least one whole book, and there is no way we can claim ourselves master of each one of them.
We will keep fixing and updating this book in the second and third editions.
Also, while the core of scientific computing keeps stable for the last several decades, its applications are changing day by day.
More state-of-art use cases should be included in the third part.

Writing this book surely feels like a long journey for me, and what a journey it is.
I joined the Owl project at about 2017, and worked on two parts: optimising the low level operations, and building high level DNN applications to verify and drive the design of Owl architecture.
Working on these two extremes gives me a great opportunity to get to know the Owl stack. To debug a neural network application, I have to understand how the modules work with each other, how the computation graph is built, and how it is affected by the performance of single operations, etc.
Some of the chapters are actually based on the learning notes of myself.
For example, the AD chapter starts with the definition of algorithmic differentiation, builds a toy implementation based on one example, and then keeps revising the solution with more and more details.
That's exactly how I learned this topic in Owl.
You can also find this learn-and-write style in several other chapters.
If you can learn something by following the way we did it, I would call this book a great success.
\textit{"For here, I hope, begins our lasting joy."}
